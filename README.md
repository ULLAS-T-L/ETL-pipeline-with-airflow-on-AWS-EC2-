****How to build and automate a python ETL pipeline with airflow on AWS EC2 | Data Engineering Project****

In this data engineering project, I learnt how to build and automate an ETL process that can extract 

Step 1 - current weather data from open weather map API

Step 2 - transform the data and load the data into an S3 bucket using Apache Airflow. 

Step 3 - Apache Airflow such as DAG and Operators 


Throughout this project, I acquired knowledge in the following areas:

1. **AWS:**
   - Explored AWS services such as IAM rules, EC2 instances, Airflow installation, S3 usage, and establishing SSH connections from Visual Studio Code to AWS.

2. **Airflow:**
   - Gained insights into Airflow, encompassing a deeper understanding of operators and the creation of Directed Acyclic Graphs (DAGs).

3. **ETL (Extract, Transform, Load):**
   - Executed ETL processes involving extraction from an API, transformation using Python scripts, and loading the transformed data into an S3 bucket.


![Architecture](https://github.com/ULLAS-T-L/ETL-pipeline-with-airflow-on-AWS-EC2-/blob/04889b9e8a0134ded04f8f218226e8babbc8b9ca/Architecture.png)




Credit - tuplespectra 
